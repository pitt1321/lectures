{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational methods in Physics\n",
    "## Week 5\n",
    "#### Prof. Michael Wood-Vasey\n",
    "##### [based on materials from Prof. Brian D'Urso]\n",
    "##### University of Pittsburgh, Department of Physics and Astronomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear algebra\n",
    "\n",
    "## Overview\n",
    "This week's topics:\n",
    "* Numerical Differentiation\n",
    "  + Forward, Central, Extrapolated Difference Methods\n",
    "  + Second derivatives\n",
    "* Writing and reading arrays to/from files.\n",
    "* Linear algebra and matrix methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Differentiation\n",
    "\n",
    "### Numerical Differentiation\n",
    "We know how to integrate numerically, how about differentiating?\n",
    "\n",
    "* Numerical derivatives are even easier than integrals!\n",
    "* Go back to definition of derivative:\n",
    "$$\n",
    "f^\\prime (x) = \\frac{d}{dx}f(x) = \\lim_{\\epsilon\\to 0} \\frac{f(x+\\epsilon)-f(x)}{\\epsilon}\n",
    "$$\n",
    "* As with integration, use finite $\\epsilon$ instead of $\\epsilon\\to 0$.\n",
    "* This will give us another piece of the puzzle for solving differential equations (ODEs and PDEs) numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Difference Method\n",
    "\n",
    "* Start with the forward difference operator $D_f\\left[f(x), h\\right]$:\n",
    "$$\n",
    "f^\\prime(x) \\simeq D_f\\left[f(x), h\\right] = \\frac{f(x+h)-f(x)}{h}\n",
    "$$\n",
    "* Compare to the Taylor expansion of $f(x+h)$:\n",
    "$$\n",
    "f(x+h) = f(x) + h f^\\prime(x) + \\frac{h^2}{2} f^{\\prime\\prime}(x) + \\cdots\n",
    "$$\n",
    "* By comparison, we see:\n",
    "$$\n",
    "D_f\\left[f(x), h\\right] = f^\\prime(x) + \\frac{h}{2} f^{\\prime\\prime}(x) + \\cdots\n",
    "\\approx f^\\prime(x) + \\mathcal{O}(h)\n",
    "$$\n",
    "* So, the error scales as $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Difference Example\n",
    "\n",
    "* Consider the function: $f(x) = a + b x^2$\n",
    "* The exact derivative is $f^\\prime(x) = 2 b x$\n",
    "* Applying the Forward Difference Approximation gives:\n",
    "$$\n",
    "f^\\prime(x) \\simeq \\frac{f(x+h)-f(x)}{h} = 2 b x + b h\n",
    "$$\n",
    "* As expected, error $\\propto h \\Rightarrow$ need very small $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement: Central Difference Method\n",
    "\n",
    "* Start with the same $h$, but make the difference symmetrical:\n",
    "$$\n",
    "f^\\prime(x) \\simeq D_{cd}\\left[f(x), h\\right] = \\frac{f(x+h/2)-f(x-h/2)}{h}\n",
    "$$\n",
    "* Again, by comparison with the Taylor series at $f(x \\pm h/2)$:\n",
    "$$\n",
    "D_{cd}\\left[f(x), h\\right] = f^\\prime(x) + \\frac{1}{24} h^2 f^{(3)}(x) + \\cdots\n",
    "\\approx f^\\prime(x) + \\mathcal{O}(h^2)\n",
    "$$\n",
    "* All even derivatives cancel.\n",
    "* Now the error $\\propto h^2$ (one order better than forward difference).\n",
    "* Exact for $f(x) = a + b x^2$.\n",
    "* Better rule $\\Rightarrow$ can use larger $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolated Difference Method\n",
    "\n",
    "* Consider the error in the central difference method:\n",
    "$$\n",
    "D_{cd}[f(x), h] \\simeq f^\\prime (x) + \\frac{1}{24}h^2 f^{\\prime\\prime\\prime}(x) + \\mathcal{O}(h^4)\n",
    "$$\n",
    "* Compare to:\n",
    "$$\n",
    "D_{cd}[f(x), h/2] \\simeq f^\\prime (x) + \\frac{1}{96}h^2 f^{\\prime\\prime\\prime}(x) + \\mathcal{O}(h^4)\n",
    "$$\n",
    "* Cancel the quadratic term using the difference between the two $\\Rightarrow$ *Extrapolated Difference Method*:\n",
    "$$\n",
    "D_{ed}[f(x), h] = \\frac{4 D_{cd}[f(x), h/2] - D_{cd}[f(x), h]}{3}\n",
    "\\approx f^\\prime (x) + \\frac{h^4 f^{(5)}(x)}{4\\times 16 \\times 120} + \\cdots\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Derivatives\n",
    "\n",
    "* Start with the central difference method:\n",
    "$$\n",
    "f^\\prime(x) \\simeq D_{cd}\\left[f(x), h\\right] = \\frac{f(x+h/2)-f(x-h/2)}{h}\n",
    "$$\n",
    "* Apply central difference method twice:\n",
    "$$f^{\\prime\\prime}(x) \\approx D_{cd}[f^\\prime (x), h] \\approx D_{cd}\\left[D_{cd}[f(x), h], h\\right]  $$\n",
    "$$                    \\approx \\frac{f^\\prime(x+h/2)-f^\\prime(x-h/2)}{h}$$  \n",
    "$$                    \\approx \\frac{[f(x+h)-f(x)]-[f(x)-f(x-h)]}{h^2}  $$\n",
    "$$                    \\approx \\frac{f(x+h)-2 f(x)+f(x-h)}{h^2}  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices\n",
    "\n",
    "#### Creating Arrays in Numpy\n",
    "* Creating arrays:\n",
    "  * Online documentation:  \n",
    "    http://docs.scipy.org/doc/numpy/reference/routines.array-creation.html\n",
    "* Writing to a file:\n",
    "  * Online documentation:  \n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.savetxt.html\n",
    "  * Python help:\n",
    "  `help(numpy.savetxt)`\n",
    "* Loading from a file:\n",
    "  * Online documentation:  \n",
    "  http://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html\n",
    "  * Python help:  \n",
    "  `help(numpy.loadtxt)`\n",
    "* There are other fileIO functions:\n",
    "  e.g. `numpy.load` and `numpy.save`.\n",
    "* and other formats (e.g., `hdf`) and frameworks (e.g., `astropy.Tables`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples: Arrays and Files\n",
    "* Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[0.0, 2.5, 3.2],\n",
    "              [1.0, 5.6, 8.9],\n",
    "              [2.0, 7.1, 3.7],\n",
    "              [3.0, 4.2, 9.3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save $\\mathbf{A}$ to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('A_test.csv', A,\n",
    "           delimiter=',', fmt='%g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the array back from the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B = np.loadtxt('A_test.csv',\n",
    "               delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   2.5  3.2]\n",
      " [ 1.   5.6  8.9]\n",
      " [ 2.   7.1  3.7]\n",
      " [ 3.   4.2  9.3]]\n"
     ]
    }
   ],
   "source": [
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Let's take a moment to look at the file. [...]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo = {\"PHYS\" : \"Physics\", \"ASTRON\" : \"Astronomy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics\n"
     ]
    }
   ],
   "source": [
    "print(foo['PHYS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHYS Physics\n",
      "ASTRON Astronomy\n"
     ]
    }
   ],
   "source": [
    "for key, value in foo.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra\n",
    "\n",
    "#### Linear Algebra Problems\n",
    "* The basic linear algebra problem is a set of $m$ simultaneous linear equations with $n$ unknowns:\n",
    "\\begin{equation*}\n",
    "\\begin{matrix}\n",
    " \\alpha_{0,0}x_0   &+& \\alpha_{0,1}x_1   &+& \\cdots &+& \\alpha_{0,n-1}x_{n-1}  &=& b_0 \\\\\n",
    " \\alpha_{1,0}x_0   &+& \\alpha_{1,1}x_1   &+& \\cdots &+& \\alpha_{1,n-1}x_{n-1}  &=& b_1 \\\\\n",
    " \\vdots            &+& \\vdots            &+& \\ddots &+& \\vdots                 &=& \\vdots \\\\\n",
    " \\alpha_{m-1,0}x_0 &+& \\alpha_{m-1,1}x_1 &+& \\cdots &+& \\alpha_{m-1,n-1}x_{n-1}&=& b_{m-1} \\\\\n",
    "\\end{matrix}\n",
    "\\end{equation*}\n",
    "* Typically, we know $\\alpha_{i,j}$ and $b_i$, and want to find $x_j$.\n",
    "* If $m>n$, the system is overdetermined.\n",
    "* If $m<n$, the system is underdetermined.\n",
    "* We will look primarily at the case $n=m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Representation\n",
    "* Computers are better able to handle equations as matrix equations.\n",
    "* Matrix representation:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{pmatrix}\n",
    "\\alpha_{0,0}   & \\alpha_{0,1}   & \\cdots & \\alpha_{0,n-1}   \\\\\n",
    "\\alpha_{1,0}   & \\alpha_{1,1}   & \\cdots & \\alpha_{1,n-1}   \\\\\n",
    "\\vdots         & \\vdots         & \\ddots & \\vdots           \\\\\n",
    "\\alpha_{m-1,0} & \\alpha_{m-1,1} & \\cdots & \\alpha_{m-1,n-1} \\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "\\vdots \\\\\n",
    "x_{n-1} \\\\\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "b_0 \\\\\n",
    "b_1 \\\\\n",
    "\\vdots \\\\\n",
    "b_{m-1} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "* We can write this set of equations in a compact form, writing the matrix as $\\mathbf{A}$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{A}\\vec{x} = \\vec{b}\n",
    "\\end{equation*}\n",
    "\n",
    "* Here $\\mathbf{A}$ is a square matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classes of Matrix Problems\n",
    "$\\mathbf{A}\\vec{x}=\\vec{b}$\n",
    "* $\\mathbf{A}$ is a known $N \\times N$ matrix.\n",
    "* $\\vec{x}$ is an unknown vector of length $N$.\n",
    "* $\\vec{b}$ is a known vector of length $N$.\n",
    "* Solve with Gaussian elimination\n",
    " or lower-upper (LU) decomposition.\n",
    "* Slower: solve by finding $\\mathbf{A}^{-1}$, then $\\vec{x}=\\mathbf{A}^{-1}\\vec{b}$.\n",
    "$\\mathbf{A}\\vec{x}=\\lambda\\vec{x}$\n",
    "* Eigenvector $\\vec{x}$ is an unknown vector of length $N$.\n",
    "* Eigenvalue $\\lambda$ is an unknown parameter.\n",
    "* $\\mathbf{A}^{-1}$ doesn't help! Need specialized solver.\n",
    "* Can shown that $\\textrm{det}[\\mathbf{A}-\\lambda\\mathbf{I}] = 0$ for eigenvalues $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Algebra Routines\n",
    "* We *will* solve linear algebra problems with \"canned\" routines.\n",
    "* Eigensystems, matrix multiplication, inverses, determinants, etc.\n",
    "* Many tested and optimized packages available:\n",
    "NETLIB, LAPACK, SLATEC, BLAS, \\ldots\n",
    "* Writing custom solvers \"from scratch\" is not usually worthwhile for these.\n",
    "* NumPy and SciPy wrap some of these.\n",
    "* We will primarily use the NumPy routines in `numpy.linalg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Algebra in Numpy\n",
    "Common linear algebra functions available in `numpy`:\n",
    "* Online documentation:\n",
    "  http://docs.scipy.org/doc/numpy/reference/routines.linalg.html\n",
    "* Python help:\n",
    "  `help(numpy.linalg)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples: Solving Linear Systems\n",
    "* Setup matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[ 1,  2,   3],\n",
    "              [22, 32,  42],\n",
    "              [55, 66, 100]])\n",
    "b = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Solve $\\mathbf{A}\\vec{x}=\\vec{b}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.4057971  -0.1884058   0.92753623]\n"
     ]
    }
   ],
   "source": [
    "x = np.linalg.solve(A, b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check accuracy of the solution by calculating $\\mathbf{A}\\vec{x}-\\vec{b}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   2.66453526e-15,   3.10862447e-15])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, x) - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Less efficient direct solution, $\\vec{x}=\\mathbf{A}^{-1}\\vec{b}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00  -4.30211422e-16  -8.88178420e-16]\n",
      " [  6.93889390e-16   1.00000000e+00  -1.77635684e-15]\n",
      " [ -8.88178420e-16  -4.44089210e-16   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "A_inverse = np.linalg.inv(A)\n",
    "\n",
    "print(np.dot(A_inverse, A))\n",
    "x = np.dot(A_inverse, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.4057971  -0.1884058   0.92753623]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
